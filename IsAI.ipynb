{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "4rYCR8sbsNcr",
        "Q58pD6k1sRDj"
      ],
      "authorship_tag": "ABX9TyNo9jcrMsBhum8CZjL3AwNd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SiphiweAI/IsAI/blob/main/IsAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scope\n",
        "- Use pretrained models that will review video, text or and/or image content and classify as being ai generated or not\n",
        "## Inputs\n",
        "- For Text - Hugging Face Transformers\n",
        "- For Images -\n",
        "- For Videos -\n",
        "## Outputs\n",
        "- Three separate models for text, image, and video detection, each trained and optimized independently.\n",
        "\n",
        "- A wrapper API or service that routes incoming data to the appropriate model based on content type.\n",
        "\n",
        "- Unified output format that reports whether the input is AI-generated, with modality-specific confidence scores."
      ],
      "metadata": {
        "id": "KjAq30iMmJmE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save and Restore Session"
      ],
      "metadata": {
        "id": "jHfCkRCy229L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dill\n",
        "dill.dump_session(r\"C:\\Users\\siphi\\OneDrive\\Documents\\Working Notebooks\\notebook_session.db\")"
      ],
      "metadata": {
        "id": "i5HFN2y-2DLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dill\n",
        "dill.load_session(r\"C:\\Users\\siphi\\OneDrive\\Documents\\Working Notebooks\\notebook_session.db\")"
      ],
      "metadata": {
        "id": "ZAwp_QXg2ldd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Model"
      ],
      "metadata": {
        "id": "PMMFpW9BsIIm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "4XINJ_OfqAW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models_info = [\n",
        "    {\"name\": \"roberta-base-openai-detector\", \"sigmoid\": True},\n",
        "    {\"name\": \"prasoonmhwr/ai_detection_model\", \"sigmoid\": True},\n",
        "    {\"name\": \"openai-community/roberta-large-openai-detector\", \"sigmoid\": True},\n",
        "]\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "7lMEIxHnsnqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = []"
      ],
      "metadata": {
        "id": "ZlOWxLg6s9xl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for m in models_info:\n",
        "    tok = AutoTokenizer.from_pretrained(m[\"name\"])\n",
        "    mdl = AutoModelForSequenceClassification.from_pretrained(m[\"name\"]).to(device)\n",
        "    mdl.eval()\n",
        "    models.append({\n",
        "        \"tokenizer\": tok,\n",
        "        \"model\": mdl,\n",
        "        \"sigmoid\": m[\"sigmoid\"]\n",
        "    })"
      ],
      "metadata": {
        "id": "k7-yDyzbt5j2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_ave(text: str) -> float:\n",
        "    \"\"\"\n",
        "    Predict average probability that the input text is AI-generated\n",
        "    by averaging outputs from multiple models.\n",
        "\n",
        "    Args:\n",
        "        text (str): Input text to classify.\n",
        "\n",
        "    Returns:\n",
        "        float: Average AI-generated probability (0 to 1).\n",
        "    \"\"\"\n",
        "    probs = []\n",
        "    with torch.no_grad():\n",
        "        for entry in models:\n",
        "            tokenizer = entry[\"tokenizer\"]\n",
        "            model = entry[\"model\"]\n",
        "            sigmoid_flag = entry[\"sigmoid\"]\n",
        "\n",
        "            inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "            outputs = model(**inputs)\n",
        "            logits = outputs.logits\n",
        "\n",
        "            if sigmoid_flag:\n",
        "                prob = torch.sigmoid(logits)[0][0].item()\n",
        "            else:\n",
        "                # If model outputs logits for two classes, apply softmax and take AI-generated class probability\n",
        "                prob = F.softmax(logits, dim=1)[0][1].item()\n",
        "\n",
        "            probs.append(prob)\n",
        "\n",
        "    avg_prob = sum(probs) / len(probs)\n",
        "    return avg_prob"
      ],
      "metadata": {
        "id": "Etm22v3Z7ypg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"In this paper, we explore...\"\n",
        "result = predict_ave(text)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "DpcmEFwC8d-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Model"
      ],
      "metadata": {
        "id": "4rYCR8sbsNcr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9LJZ0MSNsPzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S0aLb3qPsQiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Videos Model"
      ],
      "metadata": {
        "id": "Q58pD6k1sRDj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qUPAm_79sULL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}